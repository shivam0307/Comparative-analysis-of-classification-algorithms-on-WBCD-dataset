# -*- coding: utf-8 -*-
"""WBCD_Data_Analysis_and_Model_Implementation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MYdWNiKSjmAQNVS_xIFDcaI9XuEqDtir
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv("/content/drive/MyDrive/WBCD_Dataset/breast_cancer.csv")

"""#Description of the Data"""

dataset.head()

# Id column is redundant and not useful, so dropping the ID column
dataset.drop('id',axis =1,inplace=True)

dataset.head(5)

# Checking the total shape of the dataset
dataset.shape

"""The WBCD dataset, which we are using has 31 columns (excluding ID column)  and 569 records."""

# Reviewing the Data type information of the columns of WBCD dataset
dataset.info()

"""From the above information, it is clear that all the columns have values of datatype float, except diagnosis. Since, there may be possibility of missing values in the dataset."""

# Checking missing variables in the dataset
dataset.isnull().any()

dataset.diagnosis.unique()

"""So, it is clear that diagnosis is a categorical variable, because it represents a fix number of possible values (i.e, Malignant or Benign). The machine learning algorithms wants numbers, and not strings, as their inputs so we need some method of coding to convert them.

#Analyzing Multicollinearity

Summary statistics are measurements meant to describe data. In the field of descriptive statistics, there are many summary measurements.
"""

dataset.describe()

dataset.skew() # The skew result show a positive (right) or negative (left) skew. Values closer to zero show less skew.

# Group by diagnosis and review the output.
diag_gr = dataset.groupby('diagnosis', axis=0)
pd.DataFrame(diag_gr.size(), columns=['# of observations'])

"""357 observations indicating the absence of cancer cells and 212 show absence of cancer cell."""

# Checking Multicollinearity

# Set up the matplotlib figure
data, ax = plt.subplots(figsize=(30, 30))
plt.title('Breast Cancer Feature Correlation')

# Generate a mask for the upper triangle
mask = np.zeros_like(dataset.corr(), dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

# Generate a custom diverging colormap
cmap = sns.diverging_palette(260, 10, as_cmap=True)

sns.heatmap(dataset.corr(), vmax=1.2, square='square', cmap=cmap, mask=mask, 
            ax=ax,annot=True, fmt='.2g',linewidths=2)

"""There are quite a few variables that are correlated. Often we have features that are highly correlated and those provide redundant information. By eliminating highly correlated features we can avoid a predictive bias for the information contained in these features. This also shows us, that when we want to make statements about the biological/ medical importance of specific features, we need to keep in mind that just because they are suitable to predicting an outcome they are not necessarily causal - they could simply be correlated with causal factors.

I am now removing all features with a correlation higher than 0.9, keeping the feature with the lower mean.
"""

dataset = dataset.drop(["compactness_mean","concavity_mean","texture_worst","fractal_dimension_se","texture_mean","perimeter_worst","texture_se","perimeter_se","radius_mean"],axis=1)

dataset

"""#Visualizing the data using Plots

One of the main goals of visualizing the data here is to observe which features are most helpful in predicting malignant or benign cancer. The other is to see general trends that may aid us in model selection and hyper parameter selection.

Apply 3 techniques that you can use to understand each attribute of your dataset independently.

* Histograms.
* Density Plots.
* Box and Whisker Plots.
"""

hist_mean = dataset.hist(bins=10, figsize=(25, 20), grid=False,)

"""We can see that perhaps the attributes concavity, and concavity_point may have an exponential distribution. We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables."""

plt = dataset.plot(kind= 'density', subplots=True, layout=(7,3), sharex=False, 
                     sharey=False,fontsize=10, figsize=(15,15))

"""We can see that perhaps the attributes perimeter, radius, area, concavity,compactness may have an exponential distribution. We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.


"""

plt = dataset.plot(kind= 'box', subplots=True, layout=(10,3), sharex=False, sharey=False, fontsize=12, figsize=(20,50))

"""We can see that perhaps the attributes perimeter, radius, area, concavity,compactness may have an exponential distribution. We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.

#Data Label Encoding

The Processof converting categorical data into numerical data is Encoding. Since the dataset has one column named 'diagnosis', which has categorical values, we will convert those values into numeral form of 0 and 1.
"""

dataset.info()

#Assign predictors to a variable of ndarray (matrix) type
array = dataset.values
X = array[:,1:21] # features
Y = array[:,0]

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

#transform the class labels from their original string representation (M and B) into integers
Y = LabelEncoder().fit_transform(Y)

"""#Data Scaling - Normalization


"""

# Normalize the  data (center around 0 and scale to remove the variance).
scaler=StandardScaler()
X = scaler.fit_transform(X)

"""Now, we have X containg all input features from 1 to 21 and Y as the output feature. The values of X are normalized and Y are in numerical data type. Now the dataset (X,Y) is clean and can be further used in model training.

#Implementing Model Algorithms
"""

from sklearn.model_selection import train_test_split

# Divide records in training and testing sets.
X_training_data, X_testing_data, Y_training_data, Y_testing_data = train_test_split(X, Y, test_size=0.3, random_state=2, stratify=Y)

from sklearn.metrics import accuracy_score
from sklearn import metrics
from sklearn.metrics import roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import tensorflow as tf

"""##1. Logistic Regression"""

#Importing the Regression Function
logreg = LogisticRegression()

#Training the Regression Model
logreg.fit(X_training_data,Y_training_data)

#Predicting the corresponding output values for Testing Input data
Y_LR_predicted = logreg.predict(X_testing_data)

"""####Confusion Matrix for Regression Model"""

#Creating the Confusion Matrix
confusion_matrix = metrics.confusion_matrix(Y_testing_data,Y_LR_predicted)

#Displaying the Matrix
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
cm_display.plot()

"""####Accuracy, Recall, Precision and F-Score for Regression Model"""

#Accuracy 
print("Accuracy for Regression Model: ",metrics.accuracy_score(Y_testing_data,Y_LR_predicted))

#Recall
print("Recall value for Regression Model: ",metrics.recall_score(Y_testing_data,Y_LR_predicted))

#Precision
print("Precision value for Regression Model: ",metrics.precision_score(Y_testing_data,Y_LR_predicted))

#F-Score
print("F-Score for Regression Model: ",metrics.f1_score(Y_testing_data,Y_LR_predicted))

"""####Receiver Operating Characterstic Curve for Regression Model"""

# Plotting the ROC Curve
import matplotlib.pyplot as plt

probas_ = logreg.predict_proba(X_testing_data)
fpr, tpr, thresholds = roc_curve(Y_testing_data, probas_[:, 1])
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % (roc_auc))
plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for Regression')

#ROC_AUC Score for Regression
metrics.roc_auc_score(Y_testing_data,Y_LR_predicted)

"""##2. K-Nearest Neighbour"""

#Importing the K-Nearest Neighbour Function with K=7
knn = KNeighborsClassifier(n_neighbors=7)

#traing the KNN Model
knn.fit(X_training_data,Y_training_data)

#Predicting the corresponding output values fo Testing Input Data
Y_KNN_predicted = knn.predict(X_testing_data)

"""####Confusion Matrix for K-Nearest Neighbour Model"""

#Creating the Confusion Matrix
confusion_matrix = metrics.confusion_matrix(Y_testing_data,Y_KNN_predicted)

#Displaying the Matrix
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
cm_display.plot()

"""####Accuracy, Recall, Precision and F-Score for K-Nearest Neighbour Model"""

#Accuracy 
print("Accuracy for KNN Model: ",metrics.accuracy_score(Y_testing_data,Y_KNN_predicted))

#Recall
print("Recall value for KNN Model: ",metrics.recall_score(Y_testing_data,Y_KNN_predicted))

#Precision
print("Precision value for KNN Model: ",metrics.precision_score(Y_testing_data,Y_KNN_predicted))

#F-Score
print("F-Score for KNN Model: ",metrics.f1_score(Y_testing_data,Y_KNN_predicted))

"""####Receiver Operating Characterstic Curve for K-Nearest Neighbour Model"""

# Plotting the ROC Curve
import matplotlib.pyplot as plt
probas_ = knn.predict_proba(X_testing_data)
fpr, tpr, thresholds = roc_curve(Y_testing_data, probas_[:, 1])
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % (roc_auc))
plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for KNN')

#ROC_AUC Score for KNN
metrics.roc_auc_score(Y_testing_data,Y_KNN_predicted)

"""##3. Artificial Neural Network"""

#Importing the Neural Network Function
ann = tf.keras.models.Sequential()

#Adding First Hidden Layer
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Second Hidden Layer
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))

#Adding Output Layer
ann.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))

#Compiling ANN
ann.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])

#Fitting ANN
ann.fit(X_training_data,Y_training_data,batch_size=64,epochs = 100)

#Predicting the corresponding output values for Testing Input data
Y_ANN_predicted = ann.predict(X_testing_data)

#Converting float type values into binary 
Y_ANN_predicted = (Y_ANN_predicted>0.5)

"""####Confusion Matrix for Artificial Neural Network Model"""

#Creating the Confusion Matrix
confusion_matrix = metrics.confusion_matrix(Y_testing_data,Y_ANN_predicted)

#Displaying the Matrix
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
cm_display.plot()

"""####Accuracy, Recall, Precision and F-Score for Artificial Neural Network Model"""

#Accuracy 
print("Accuracy for ANN Model: ",metrics.accuracy_score(Y_testing_data,Y_ANN_predicted))

#Recall
print("Recall value for ANN Model: ",metrics.recall_score(Y_testing_data,Y_ANN_predicted))

#Precision
print("Precision value for ANN Model: ",metrics.precision_score(Y_testing_data,Y_ANN_predicted))

#F-Score
print("F-Score for ANN Model: ",metrics.f1_score(Y_testing_data,Y_ANN_predicted))

"""####Receiver Operating Characterstic Curve for Artificial Neural Network Model"""

# Plotting the ROC Curve
import matplotlib.pyplot as plt
probas_ = ann.predict(X_testing_data)
fpr, tpr, thresholds = roc_curve(Y_testing_data, probas_[:,])
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % (roc_auc))
plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for ANN')

#ROC_AUC Score for ANN
metrics.roc_auc_score(Y_testing_data,Y_ANN_predicted)